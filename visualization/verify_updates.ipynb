{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f6d305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows: 170\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>global_acc</th>\n",
       "      <th>manifest_cid</th>\n",
       "      <th>node_id</th>\n",
       "      <th>samples</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>claimed_acc</th>\n",
       "      <th>eval_acc</th>\n",
       "      <th>acc_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>balance</th>\n",
       "      <th>stake_penalty</th>\n",
       "      <th>stake</th>\n",
       "      <th>reputation</th>\n",
       "      <th>malicious_detected</th>\n",
       "      <th>committee</th>\n",
       "      <th>is_malicious</th>\n",
       "      <th>strategy</th>\n",
       "      <th>exp</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7703</td>\n",
       "      <td>Qm00000022</td>\n",
       "      <td>0</td>\n",
       "      <td>7682</td>\n",
       "      <td>0.353403</td>\n",
       "      <td>0.914150</td>\n",
       "      <td>0.9141</td>\n",
       "      <td>0.6532</td>\n",
       "      <td>0.2609</td>\n",
       "      <td>...</td>\n",
       "      <td>74.5680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.5680</td>\n",
       "      <td>19.5688</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>benign</td>\n",
       "      <td>20250813-223511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7703</td>\n",
       "      <td>Qm00000022</td>\n",
       "      <td>1</td>\n",
       "      <td>6725</td>\n",
       "      <td>0.203163</td>\n",
       "      <td>0.945145</td>\n",
       "      <td>0.9451</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>0.5963</td>\n",
       "      <td>...</td>\n",
       "      <td>39.7479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.7479</td>\n",
       "      <td>19.0325</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>benign</td>\n",
       "      <td>20250813-223511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7703</td>\n",
       "      <td>Qm00000022</td>\n",
       "      <td>2</td>\n",
       "      <td>1321</td>\n",
       "      <td>0.341979</td>\n",
       "      <td>0.912869</td>\n",
       "      <td>0.9129</td>\n",
       "      <td>0.3931</td>\n",
       "      <td>0.5198</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0427</td>\n",
       "      <td>18.4381</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>benign</td>\n",
       "      <td>20250813-223511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   round  global_acc manifest_cid  node_id  samples      loss       acc  \\\n",
       "0      0      0.7703   Qm00000022        0     7682  0.353403  0.914150   \n",
       "1      0      0.7703   Qm00000022        1     6725  0.203163  0.945145   \n",
       "2      0      0.7703   Qm00000022        2     1321  0.341979  0.912869   \n",
       "\n",
       "   claimed_acc  eval_acc  acc_diff  ...  balance stake_penalty     stake  \\\n",
       "0       0.9141    0.6532    0.2609  ...  74.5680           0.0  174.5680   \n",
       "1       0.9451    0.3488    0.5963  ...  39.7479           0.0  139.7479   \n",
       "2       0.9129    0.3931    0.5198  ...  26.0427           0.0  126.0427   \n",
       "\n",
       "   reputation  malicious_detected  committee  is_malicious  strategy     exp  \\\n",
       "0     19.5688                   1          1             0      none  benign   \n",
       "1     19.0325                   1          1             0      none  benign   \n",
       "2     18.4381                   1          1             0      none  benign   \n",
       "\n",
       "                ts  \n",
       "0  20250813-223511  \n",
       "1  20250813-223511  \n",
       "2  20250813-223511  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Federated Learning Model Update Verification\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from flsim.storage import IPFSSim\n",
    "\n",
    "\n",
    "def load_all_runs(runs_root: Path) -> pd.DataFrame:\n",
    "    runs_root = runs_root if runs_root.name == \"runs\" else (runs_root / \"runs\")\n",
    "    rows = []\n",
    "    if not runs_root.exists():\n",
    "        print(\"No runs folder found:\", runs_root)\n",
    "        return pd.DataFrame()\n",
    "    for exp_dir in sorted(runs_root.glob(\"*\")):\n",
    "        if not exp_dir.is_dir():\n",
    "            continue\n",
    "        for ts_dir in sorted(exp_dir.glob(\"*\")):\n",
    "            csv_path = ts_dir / \"fl_log.csv\"\n",
    "            if csv_path.exists():\n",
    "                try:\n",
    "                    df = pd.read_csv(csv_path)\n",
    "                    df[\"exp\"] = exp_dir.name\n",
    "                    df[\"ts\"] = ts_dir.name\n",
    "                    rows.append(df)\n",
    "                except Exception as e:\n",
    "                    print(\"Failed to read\", csv_path, e)\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "    return pd.concat(rows, ignore_index=True)\n",
    "\n",
    "\n",
    "BASE = Path(\"/Users/yuandouwang/Documents/projects/federated_lab/runs\")  # TODO: change to your project path\n",
    "df = load_all_runs(BASE)\n",
    "print(\"Loaded rows:\", len(df))\n",
    "df.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80ff5d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from: /Users/yuandouwang/Documents/projects/federated_lab/runs/benign/20250813-223511/models\n",
      "✅ Loaded model global_round_0.pt\n",
      "✅ Loaded model global_round_1.pt\n",
      "✅ Loaded model global_round_2.pt\n",
      "✅ Loaded model global_round_3.pt\n",
      "✅ Loaded model global_round_4.pt\n",
      "Loading models from: /Users/yuandouwang/Documents/projects/federated_lab/runs/benign/20250813-223907/models\n",
      "✅ Loaded model global_round_0.pt\n",
      "✅ Loaded model global_round_1.pt\n",
      "✅ Loaded model global_round_2.pt\n",
      "✅ Loaded model global_round_3.pt\n",
      "✅ Loaded model global_round_4.pt\n",
      "✅ Loaded model global_round_5.pt\n",
      "Loading models from: /Users/yuandouwang/Documents/projects/federated_lab/runs/benign/20250813-224933/models\n",
      "✅ Loaded model global_round_0.pt\n",
      "✅ Loaded model global_round_0_base.pt\n",
      "✅ Loaded model global_round_1.pt\n",
      "✅ Loaded model global_round_1_base.pt\n",
      "✅ Loaded model global_round_2.pt\n",
      "✅ Loaded model global_round_2_base.pt\n",
      "✅ Loaded model global_round_3.pt\n",
      "✅ Loaded model global_round_3_base.pt\n",
      "✅ Loaded model global_round_4.pt\n",
      "✅ Loaded model global_round_4_base.pt\n",
      "✅ Loaded model global_round_5.pt\n",
      "✅ Loaded model global_round_5_base.pt\n",
      "Loaded 23 models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp</th>\n",
       "      <th>ts</th>\n",
       "      <th>round</th>\n",
       "      <th>fname</th>\n",
       "      <th>state_dict</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>benign</td>\n",
       "      <td>20250813-223511</td>\n",
       "      <td>0</td>\n",
       "      <td>global_round_0.pt</td>\n",
       "      <td>{'fc.weight': [[tensor(-0.0332), tensor(0.0229...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>benign</td>\n",
       "      <td>20250813-223511</td>\n",
       "      <td>1</td>\n",
       "      <td>global_round_1.pt</td>\n",
       "      <td>{'fc.weight': [[tensor(-0.0332), tensor(0.0229...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>benign</td>\n",
       "      <td>20250813-223511</td>\n",
       "      <td>2</td>\n",
       "      <td>global_round_2.pt</td>\n",
       "      <td>{'fc.weight': [[tensor(-0.0332), tensor(0.0229...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      exp               ts  round              fname  \\\n",
       "0  benign  20250813-223511      0  global_round_0.pt   \n",
       "1  benign  20250813-223511      1  global_round_1.pt   \n",
       "2  benign  20250813-223511      2  global_round_2.pt   \n",
       "\n",
       "                                          state_dict model  \n",
       "0  {'fc.weight': [[tensor(-0.0332), tensor(0.0229...  None  \n",
       "1  {'fc.weight': [[tensor(-0.0332), tensor(0.0229...  None  \n",
       "2  {'fc.weight': [[tensor(-0.0332), tensor(0.0229...  None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def load_all_global_models(runs_root: Path, model_class=None, device='cpu'):\n",
    "    runs_root = runs_root if runs_root.name == \"runs\" else (runs_root / \"runs\")\n",
    "    rows = []\n",
    "\n",
    "    if not runs_root.exists():\n",
    "        print(\"No runs folder found:\", runs_root)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for exp_dir in sorted(runs_root.glob(\"*\")):\n",
    "        if not exp_dir.is_dir():\n",
    "            continue\n",
    "        for ts_dir in sorted(exp_dir.glob(\"*\")):\n",
    "            models_dir = ts_dir / \"models\"\n",
    "            if not models_dir.exists():\n",
    "                continue\n",
    "\n",
    "            print(f\"Loading models from: {models_dir}\")\n",
    "            for fname in sorted(os.listdir(models_dir)):\n",
    "                if fname.endswith('.pt') or fname.endswith('.pth'):\n",
    "                    fpath = models_dir / fname\n",
    "                    try:\n",
    "                        state_dict = torch.load(fpath, map_location=device)\n",
    "                        model = None\n",
    "                        if model_class is not None:\n",
    "                            model = model_class().to(device)\n",
    "                            model.load_state_dict(state_dict, strict=False)\n",
    "                            model.eval()\n",
    "\n",
    "                        # Extract round number if in filename (e.g., \"global_round_3.pt\")\n",
    "                        round_num = None\n",
    "                        if \"round\" in fname:\n",
    "                            try:\n",
    "                                round_num = int(\"\".join([c for c in fname if c.isdigit()]))\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "\n",
    "                        rows.append({\n",
    "                            \"exp\": exp_dir.name,\n",
    "                            \"ts\": ts_dir.name,\n",
    "                            \"round\": round_num,\n",
    "                            \"fname\": fname,\n",
    "                            \"state_dict\": state_dict,\n",
    "                            \"model\": model\n",
    "                        })\n",
    "                        print(f\"✅ Loaded model {fname}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"❌ Failed to load {fpath}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Example usage\n",
    "BASE = Path(\"/Users/yuandouwang/Documents/projects/federated_lab/runs\")  # Change to your project path\n",
    "models_df = load_all_global_models(BASE)\n",
    "print(f\"Loaded {len(models_df)} models\")\n",
    "models_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e01eab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [(0, 'Qm00000001', 'delta', 0.91415), (1, 'Qm00000003', 'delta', 0.945145), (2, 'Qm00000005', 'delta', 0.912869), (3, 'Qm00000007', 'delta', 0.900925), (4, 'Qm00000009', 'delta', 0.924696), (5, 'Qm00000011', 'delta', 0.901916), (6, 'Qm00000013', 'delta', 0.881536), (7, 'Qm00000015', 'delta', 0.907874), (8, 'Qm00000017', 'delta', 0.921027), (9, 'Qm00000019', 'delta', 0.891692), (0, 'Qm00000001', 'delta', 0.913603), (1, 'Qm00000003', 'delta', 0.94516), (2, 'Qm00000005', 'delta', 0.913096), (3, 'Qm00000007', 'delta', 0.899948), (4, 'Qm00000009', 'delta', 0.923776), (5, 'Qm00000011', 'delta', 0.902349), (6, 'Qm00000013', 'delta', 0.881231), (7, 'Qm00000015', 'delta', 0.908131), (8, 'Qm00000017', 'delta', 0.920704), (9, 'Qm00000019', 'delta', 0.892296), (0, 'Qm00000001', 'delta', 0.913213), (1, 'Qm00000003', 'delta', 0.944625), (2, 'Qm00000005', 'delta', 0.912263), (3, 'Qm00000007', 'delta', 0.899782), (4, 'Qm00000009', 'delta', 0.92266), (5, 'Qm00000011', 'delta', 0.901628), (6, 'Qm00000013', 'delta', 0.87979), (7, 'Qm00000015', 'delta', 0.908088), (8, 'Qm00000017', 'delta', 0.919989), (9, 'Qm00000019', 'delta', 0.891782)], 1: [(0, 'Qm00000023', 'delta', 0.932674), (1, 'Qm00000025', 'delta', 0.956327), (2, 'Qm00000027', 'delta', 0.952082), (3, 'Qm00000029', 'delta', 0.924644), (4, 'Qm00000031', 'delta', 0.946455), (5, 'Qm00000033', 'delta', 0.932681), (6, 'Qm00000035', 'delta', 0.923352), (7, 'Qm00000037', 'delta', 0.926979), (8, 'Qm00000039', 'delta', 0.943604), (9, 'Qm00000041', 'delta', 0.926828), (0, 'Qm00000023', 'delta', 0.933025), (1, 'Qm00000025', 'delta', 0.956491), (2, 'Qm00000027', 'delta', 0.953899), (3, 'Qm00000029', 'delta', 0.924259), (4, 'Qm00000031', 'delta', 0.945319), (5, 'Qm00000033', 'delta', 0.932351), (6, 'Qm00000035', 'delta', 0.923527), (7, 'Qm00000037', 'delta', 0.927288), (8, 'Qm00000039', 'delta', 0.942634), (9, 'Qm00000041', 'delta', 0.926375), (0, 'Qm00000023', 'delta', 0.933481), (1, 'Qm00000025', 'delta', 0.956684), (2, 'Qm00000027', 'delta', 0.952157), (3, 'Qm00000029', 'delta', 0.924353), (4, 'Qm00000031', 'delta', 0.945789), (5, 'Qm00000033', 'delta', 0.933649), (6, 'Qm00000035', 'delta', 0.924051), (7, 'Qm00000037', 'delta', 0.927082), (8, 'Qm00000039', 'delta', 0.94262), (9, 'Qm00000041', 'delta', 0.927674)], 2: [(0, 'Qm00000045', 'delta', 0.938493), (1, 'Qm00000047', 'delta', 0.959405), (2, 'Qm00000049', 'delta', 0.958592), (3, 'Qm00000051', 'delta', 0.930329), (4, 'Qm00000053', 'delta', 0.952409), (5, 'Qm00000055', 'delta', 0.939893), (6, 'Qm00000057', 'delta', 0.929943), (7, 'Qm00000059', 'delta', 0.931837), (8, 'Qm00000061', 'delta', 0.947918), (9, 'Qm00000063', 'delta', 0.934139), (0, 'Qm00000045', 'delta', 0.93831), (1, 'Qm00000047', 'delta', 0.959108), (2, 'Qm00000049', 'delta', 0.959198), (3, 'Qm00000051', 'delta', 0.930215), (4, 'Qm00000053', 'delta', 0.951586), (5, 'Qm00000055', 'delta', 0.939769), (6, 'Qm00000057', 'delta', 0.928765), (7, 'Qm00000059', 'delta', 0.932351), (8, 'Qm00000061', 'delta', 0.947918), (9, 'Qm00000063', 'delta', 0.933746), (0, 'Qm00000045', 'delta', 0.938558), (1, 'Qm00000047', 'delta', 0.959509), (2, 'Qm00000049', 'delta', 0.959879), (3, 'Qm00000051', 'delta', 0.930101), (4, 'Qm00000053', 'delta', 0.951547), (5, 'Qm00000055', 'delta', 0.939707), (6, 'Qm00000057', 'delta', 0.928896), (7, 'Qm00000059', 'delta', 0.932557), (8, 'Qm00000061', 'delta', 0.947648), (9, 'Qm00000063', 'delta', 0.934562)], 3: [(0, 'Qm00000067', 'delta', 0.940914), (1, 'Qm00000069', 'delta', 0.961829), (2, 'Qm00000071', 'delta', 0.960409), (3, 'Qm00000073', 'delta', 0.933687), (4, 'Qm00000075', 'delta', 0.955131), (5, 'Qm00000077', 'delta', 0.942304), (6, 'Qm00000079', 'delta', 0.931951), (7, 'Qm00000081', 'delta', 0.935118), (8, 'Qm00000083', 'delta', 0.95029), (9, 'Qm00000085', 'delta', 0.93719), (0, 'Qm00000067', 'delta', 0.941083), (1, 'Qm00000069', 'delta', 0.961279), (2, 'Qm00000071', 'delta', 0.960712), (3, 'Qm00000073', 'delta', 0.933333), (4, 'Qm00000075', 'delta', 0.954759), (5, 'Qm00000077', 'delta', 0.941521), (6, 'Qm00000079', 'delta', 0.932257), (7, 'Qm00000081', 'delta', 0.935649), (8, 'Qm00000083', 'delta', 0.95029), (9, 'Qm00000085', 'delta', 0.937825), (0, 'Qm00000067', 'delta', 0.941122), (1, 'Qm00000069', 'delta', 0.961145), (2, 'Qm00000071', 'delta', 0.961771), (3, 'Qm00000073', 'delta', 0.933073), (4, 'Qm00000075', 'delta', 0.954328), (5, 'Qm00000077', 'delta', 0.941768), (6, 'Qm00000079', 'delta', 0.93134), (7, 'Qm00000081', 'delta', 0.935692), (8, 'Qm00000083', 'delta', 0.949953), (9, 'Qm00000085', 'delta', 0.938127)], 4: [(0, 'Qm00000089', 'delta', 0.943049), (1, 'Qm00000091', 'delta', 0.962885), (2, 'Qm00000093', 'delta', 0.961696), (3, 'Qm00000095', 'delta', 0.935766), (4, 'Qm00000097', 'delta', 0.956796), (5, 'Qm00000099', 'delta', 0.94319), (6, 'Qm00000101', 'delta', 0.934352), (7, 'Qm00000103', 'delta', 0.937192), (8, 'Qm00000105', 'delta', 0.951961), (9, 'Qm00000107', 'delta', 0.94006), (0, 'Qm00000089', 'delta', 0.94353), (1, 'Qm00000091', 'delta', 0.962632), (2, 'Qm00000093', 'delta', 0.961469), (3, 'Qm00000095', 'delta', 0.935641), (4, 'Qm00000097', 'delta', 0.956404), (5, 'Qm00000099', 'delta', 0.942695), (6, 'Qm00000101', 'delta', 0.934265), (7, 'Qm00000103', 'delta', 0.937269), (8, 'Qm00000105', 'delta', 0.952743), (9, 'Qm00000107', 'delta', 0.940574), (0, 'Qm00000089', 'delta', 0.942905), (1, 'Qm00000091', 'delta', 0.962691), (2, 'Qm00000093', 'delta', 0.961771), (3, 'Qm00000095', 'delta', 0.935537), (4, 'Qm00000097', 'delta', 0.956189), (5, 'Qm00000099', 'delta', 0.942798), (6, 'Qm00000101', 'delta', 0.933348), (7, 'Qm00000103', 'delta', 0.937337), (8, 'Qm00000105', 'delta', 0.952204), (9, 'Qm00000107', 'delta', 0.939637)], 5: [(0, 'Qm00000111', 'delta', 0.944845), (1, 'Qm00000113', 'delta', 0.963509), (2, 'Qm00000115', 'delta', 0.961847), (3, 'Qm00000117', 'delta', 0.937075), (4, 'Qm00000119', 'delta', 0.957697), (5, 'Qm00000121', 'delta', 0.944467), (6, 'Qm00000123', 'delta', 0.935661), (7, 'Qm00000125', 'delta', 0.939059), (8, 'Qm00000127', 'delta', 0.95374), (9, 'Qm00000129', 'delta', 0.942024), (0, 'Qm00000111', 'delta', 0.944637), (1, 'Qm00000113', 'delta', 0.964149), (2, 'Qm00000115', 'delta', 0.962604), (3, 'Qm00000117', 'delta', 0.937096), (4, 'Qm00000119', 'delta', 0.957775), (5, 'Qm00000121', 'delta', 0.943684), (6, 'Qm00000123', 'delta', 0.934963), (7, 'Qm00000125', 'delta', 0.939188), (8, 'Qm00000127', 'delta', 0.953525), (9, 'Qm00000129', 'delta', 0.941752)]}\n"
     ]
    }
   ],
   "source": [
    "def extract_model_updates_from_df(df: pd.DataFrame):\n",
    "    \n",
    "    updates_map = {}\n",
    "    for _, row in df.iterrows():\n",
    "        if \"round\" not in row:\n",
    "            continue\n",
    "        r = int(row[\"round\"])\n",
    "        if pd.notna(row.get(\"model_update_cid\")):\n",
    "            nid = int(row[\"node_id\"])\n",
    "            updates_map.setdefault(r, []).append(\n",
    "                (nid, row[\"model_update_cid\"], row.get(\"update_type\", \"delta\"), row.get(\"acc\", None))\n",
    "            )\n",
    "    return updates_map\n",
    "\n",
    "updates_map  = extract_model_updates_from_df(df)\n",
    "\n",
    "print(updates_map)\n",
    "# print(globals_map)\n",
    "ipfs = IPFSSim()\n",
    "# agg = Aggregator(ipfs, None, [], save_dir=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3032cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d83f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# uses your updated eval.py\n",
    "from flsim.eval import evaluate_reconstructed_batch\n",
    "\n",
    "\n",
    "# --------- filename parsers ---------\n",
    "\n",
    "_RX_GLOBAL = re.compile(r\"^global_round_(\\d+)_base\\.(pt|pth)$\")\n",
    "_RX_DELTA  = re.compile(r\"^round_(\\d+)_node_(\\d+)_delta\\.(pt|pth)$\")\n",
    "\n",
    "\n",
    "def _index_globals(models_dir: Path) -> Dict[int, dict]:\n",
    "    \"\"\"Scan models/ for global_round_{r}.pt -> {r: state_dict}.\"\"\"\n",
    "    out: Dict[int, dict] = {}\n",
    "    if not models_dir.exists():\n",
    "        return out\n",
    "    for fname in os.listdir(models_dir):\n",
    "        m = _RX_GLOBAL.match(fname)\n",
    "        if not m:\n",
    "            continue\n",
    "        r = int(m.group(1))\n",
    "        fpath = models_dir / fname\n",
    "        try:\n",
    "            out[r] = torch.load(fpath, map_location=\"cpu\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Failed to load {fpath}: {e}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def _index_updates(updates_dir: Path) -> Dict[int, Dict[int, dict]]:\n",
    "    \"\"\"\n",
    "    Scan updates/ for round_{r}_node_{nid}_delta.pt\n",
    "    -> { r: { nid: delta_state_dict } }.\n",
    "    \"\"\"\n",
    "    out: Dict[int, Dict[int, dict]] = {}\n",
    "    if not updates_dir.exists():\n",
    "        return out\n",
    "    for fname in os.listdir(updates_dir):\n",
    "        m = _RX_DELTA.match(fname)\n",
    "        if not m:\n",
    "            continue\n",
    "        r   = int(m.group(1))\n",
    "        nid = int(m.group(2))\n",
    "        fpath = updates_dir / fname\n",
    "        try:\n",
    "            sd = torch.load(fpath, map_location=\"cpu\")\n",
    "            out.setdefault(r, {})[nid] = sd\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Failed to load {fpath}: {e}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# --------- reconstruction + evaluation ---------\n",
    "\n",
    "def reconstruct_and_eval_one_run(\n",
    "    run_dir: Path,                      # e.g. .../runs/<exp>/<ts>\n",
    "    *,\n",
    "    dataset: str = \"mnist\",\n",
    "    model_hint: Optional[str] = \"linear-mnist\",\n",
    "    max_workers: int = 4,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For a single run folder with:\n",
    "      models/global_round_{r}.pt\n",
    "      updates/round_{r}_node_{nid}_delta.pt\n",
    "    reconstruct base+delta for each (r, nid) and evaluate accuracy.\n",
    "\n",
    "    Returns a DataFrame with columns:\n",
    "      ['round','node_id','eval_acc','exp','ts']\n",
    "    \"\"\"\n",
    "    models_dir  = run_dir / \"models\"\n",
    "    updates_dir = run_dir / \"updates\"\n",
    "\n",
    "    globals_map  = _index_globals(models_dir)           # {r: global_state at r}\n",
    "    print(f\"Found {len(globals_map)} global models in {models_dir}\", globals_map)\n",
    "    updates_map  = _index_updates(updates_dir)          # {r: {nid: delta}}\n",
    "    print(f\"Found {len(updates_map)} rounds with updates in {updates_dir}\", updates_map)\n",
    "    if not globals_map or not updates_map:\n",
    "        print(f\"Nothing to evaluate in {run_dir}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # for round r, the base is global at r-1\n",
    "    rounds = sorted(updates_map.keys())\n",
    "\n",
    "    rows = []\n",
    "    for r in rounds:\n",
    "        base_r_minus_1 = globals_map.get(r)\n",
    "        if base_r_minus_1 is None:\n",
    "            # if round 0 has no base, skip or add your own initial_global.pt logic here\n",
    "            print(f\"⚠️ Missing base model for round {r} (need global_round_{r-1}.pt) in {models_dir}\")\n",
    "            continue\n",
    "\n",
    "        # collect deltas & node order\n",
    "        nid_list = sorted(updates_map[r].keys())\n",
    "        deltas   = [updates_map[r][nid] for nid in nid_list]\n",
    "\n",
    "        # evaluate reconstructed models: base + delta\n",
    "        accs = evaluate_reconstructed_batch(\n",
    "            base_state=base_r_minus_1,\n",
    "            deltas=deltas,\n",
    "            dataset=dataset,\n",
    "            model_hint=model_hint,\n",
    "            max_workers=max_workers,\n",
    "        )\n",
    "\n",
    "        for nid, acc in zip(nid_list, accs):\n",
    "            rows.append({\n",
    "                \"round\": r,\n",
    "                \"node_id\": nid,\n",
    "                \"eval_acc\": float(acc),\n",
    "                \"exp\": run_dir.parent.name,\n",
    "                \"ts\": run_dir.name,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def reconstruct_and_eval_all_runs(\n",
    "    runs_root: Path,                    # either .../runs or the project root containing /runs\n",
    "    *,\n",
    "    dataset: str = \"mnist\",\n",
    "    model_hint: Optional[str] = \"linear-mnist\",\n",
    "    max_workers: int = 4,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Walk through runs/*/* and evaluate all runs.\n",
    "    \"\"\"\n",
    "    runs_root = runs_root if runs_root.name == \"runs\" else (runs_root / \"runs\")\n",
    "    all_rows = []\n",
    "    if not runs_root.exists():\n",
    "        print(\"No runs folder found:\", runs_root)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for exp_dir in sorted(runs_root.glob(\"*\")):\n",
    "        if not exp_dir.is_dir(): \n",
    "            continue\n",
    "        for ts_dir in sorted(exp_dir.glob(\"*\")):\n",
    "            if not ts_dir.is_dir(): \n",
    "                continue\n",
    "            df_run = reconstruct_and_eval_one_run(\n",
    "                ts_dir,\n",
    "                dataset=dataset,\n",
    "                model_hint=model_hint,\n",
    "                max_workers=max_workers,\n",
    "            )\n",
    "            if not df_run.empty:\n",
    "                all_rows.append(df_run)\n",
    "\n",
    "    return pd.concat(all_rows, ignore_index=True) if all_rows else pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66249021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 global models in /Users/yuandouwang/Documents/projects/federated_lab/runs/benign/20250813-224933/models {1: {'fc.weight': tensor([[ 0.0091,  0.0308, -0.0257,  ...,  0.0206, -0.0344,  0.0173],\n",
      "        [-0.0268,  0.0029,  0.0045,  ...,  0.0275,  0.0335, -0.0069],\n",
      "        [-0.0076,  0.0066,  0.0051,  ..., -0.0219,  0.0033, -0.0072],\n",
      "        ...,\n",
      "        [ 0.0025,  0.0129,  0.0086,  ..., -0.0150, -0.0057, -0.0106],\n",
      "        [ 0.0336,  0.0015, -0.0280,  ..., -0.0304, -0.0030, -0.0251],\n",
      "        [-0.0256,  0.0222, -0.0286,  ...,  0.0112,  0.0251, -0.0348]]), 'fc.bias': tensor([-0.0946,  0.2198, -0.0476, -0.1155,  0.0483,  0.3540, -0.0457,  0.1803,\n",
      "        -0.3515, -0.0569])}, 5: {'fc.weight': tensor([[ 0.0091,  0.0308, -0.0257,  ...,  0.0206, -0.0344,  0.0173],\n",
      "        [-0.0268,  0.0029,  0.0045,  ...,  0.0275,  0.0335, -0.0069],\n",
      "        [-0.0076,  0.0066,  0.0051,  ..., -0.0219,  0.0033, -0.0072],\n",
      "        ...,\n",
      "        [ 0.0025,  0.0129,  0.0086,  ..., -0.0150, -0.0057, -0.0106],\n",
      "        [ 0.0336,  0.0015, -0.0280,  ..., -0.0304, -0.0030, -0.0251],\n",
      "        [-0.0256,  0.0222, -0.0286,  ...,  0.0112,  0.0251, -0.0348]]), 'fc.bias': tensor([-0.1877,  0.3235, -0.0563, -0.1990,  0.0167,  0.7685, -0.0865,  0.3654,\n",
      "        -0.7349, -0.1190])}, 4: {'fc.weight': tensor([[ 0.0091,  0.0308, -0.0257,  ...,  0.0206, -0.0344,  0.0173],\n",
      "        [-0.0268,  0.0029,  0.0045,  ...,  0.0275,  0.0335, -0.0069],\n",
      "        [-0.0076,  0.0066,  0.0051,  ..., -0.0219,  0.0033, -0.0072],\n",
      "        ...,\n",
      "        [ 0.0025,  0.0129,  0.0086,  ..., -0.0150, -0.0057, -0.0106],\n",
      "        [ 0.0336,  0.0015, -0.0280,  ..., -0.0304, -0.0030, -0.0251],\n",
      "        [-0.0256,  0.0222, -0.0286,  ...,  0.0112,  0.0251, -0.0348]]), 'fc.bias': tensor([-0.1682,  0.3051, -0.0570, -0.1813,  0.0241,  0.6810, -0.0775,  0.3282,\n",
      "        -0.6574, -0.1065])}, 0: {'fc.weight': tensor([[ 0.0091,  0.0308, -0.0257,  ...,  0.0206, -0.0344,  0.0173],\n",
      "        [-0.0268,  0.0029,  0.0045,  ...,  0.0275,  0.0335, -0.0069],\n",
      "        [-0.0076,  0.0066,  0.0051,  ..., -0.0219,  0.0033, -0.0072],\n",
      "        ...,\n",
      "        [ 0.0025,  0.0129,  0.0086,  ..., -0.0150, -0.0057, -0.0106],\n",
      "        [ 0.0336,  0.0015, -0.0280,  ..., -0.0304, -0.0030, -0.0251],\n",
      "        [-0.0256,  0.0222, -0.0286,  ...,  0.0112,  0.0251, -0.0348]]), 'fc.bias': tensor([-0.0659,  0.1520, -0.0291, -0.0761,  0.0535,  0.2123, -0.0271,  0.1037,\n",
      "        -0.2079, -0.0249])}, 3: {'fc.weight': tensor([[ 0.0091,  0.0308, -0.0257,  ...,  0.0206, -0.0344,  0.0173],\n",
      "        [-0.0268,  0.0029,  0.0045,  ...,  0.0275,  0.0335, -0.0069],\n",
      "        [-0.0076,  0.0066,  0.0051,  ..., -0.0219,  0.0033, -0.0072],\n",
      "        ...,\n",
      "        [ 0.0025,  0.0129,  0.0086,  ..., -0.0150, -0.0057, -0.0106],\n",
      "        [ 0.0336,  0.0015, -0.0280,  ..., -0.0304, -0.0030, -0.0251],\n",
      "        [-0.0256,  0.0222, -0.0286,  ...,  0.0112,  0.0251, -0.0348]]), 'fc.bias': tensor([-0.1472,  0.2828, -0.0582, -0.1629,  0.0360,  0.5836, -0.0670,  0.2861,\n",
      "        -0.5683, -0.0943])}, 2: {'fc.weight': tensor([[ 0.0091,  0.0308, -0.0257,  ...,  0.0206, -0.0344,  0.0173],\n",
      "        [-0.0268,  0.0029,  0.0045,  ...,  0.0275,  0.0335, -0.0069],\n",
      "        [-0.0076,  0.0066,  0.0051,  ..., -0.0219,  0.0033, -0.0072],\n",
      "        ...,\n",
      "        [ 0.0025,  0.0129,  0.0086,  ..., -0.0150, -0.0057, -0.0106],\n",
      "        [ 0.0336,  0.0015, -0.0280,  ..., -0.0304, -0.0030, -0.0251],\n",
      "        [-0.0256,  0.0222, -0.0286,  ...,  0.0112,  0.0251, -0.0348]]), 'fc.bias': tensor([-0.1214,  0.2562, -0.0552, -0.1422,  0.0442,  0.4753, -0.0568,  0.2374,\n",
      "        -0.4690, -0.0779])}}\n",
      "Found 6 rounds with updates in /Users/yuandouwang/Documents/projects/federated_lab/runs/benign/20250813-224933/updates {3: {9: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0083, -0.0674, -0.0659, -0.0486,  0.0028,  0.2502, -0.0096, -0.0779,\n",
      "        -0.0655,  0.0902])}, 8: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0386,  0.1135, -0.0949, -0.0600, -0.0341,  0.0666, -0.0146,  0.2664,\n",
      "        -0.1055, -0.0988])}, 3: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0721,  0.1514, -0.0510, -0.0868,  0.0297,  0.2048, -0.0654,  0.1434,\n",
      "        -0.1359, -0.1180])}, 2: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0839, -0.0150,  0.0953, -0.0289, -0.0559, -0.0528, -0.0274,  0.0418,\n",
      "        -0.0032, -0.0379])}, 4: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0170, -0.0691, -0.0350,  0.2320,  0.0944, -0.1048, -0.0552,  0.0296,\n",
      "        -0.0541, -0.0548])}, 5: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0144, -0.0343,  0.2541, -0.0293, -0.0498, -0.0328, -0.0555,  0.1016,\n",
      "        -0.0818, -0.0577])}, 0: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0117,  0.0316, -0.0247, -0.0783,  0.0438,  0.1574,  0.0661, -0.0690,\n",
      "        -0.0966, -0.0185])}, 1: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0422, -0.0592, -0.0491, -0.0706, -0.0160,  0.4255, -0.0580, -0.0449,\n",
      "        -0.1199, -0.0500])}, 7: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0734,  0.0059,  0.0383,  0.0291, -0.0612, -0.0320,  0.0454, -0.0009,\n",
      "        -0.1082,  0.1570])}, 6: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0036,  0.0644,  0.0554, -0.0298, -0.0929,  0.1194,  0.0439, -0.0146,\n",
      "        -0.0719, -0.0703])}}, 1: {7: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0677,  0.0534,  0.0016, -0.0121, -0.0623, -0.0186,  0.0445,  0.0299,\n",
      "        -0.1069,  0.1382])}, 6: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0200,  0.0952,  0.0392, -0.0468, -0.0959,  0.1441,  0.0377,  0.0018,\n",
      "        -0.0735, -0.0817])}, 0: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0325,  0.0716, -0.0600, -0.0889,  0.0483,  0.2105,  0.0390, -0.0529,\n",
      "        -0.0919, -0.0433])}, 1: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0323, -0.0523, -0.0507, -0.0749, -0.0227,  0.4952, -0.0517, -0.0419,\n",
      "        -0.1788, -0.0546])}, 4: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0110, -0.0622, -0.0310,  0.2502,  0.1116, -0.1044, -0.0602,  0.0499,\n",
      "        -0.1020, -0.0630])}, 5: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0125, -0.0099,  0.2506, -0.0579, -0.0485, -0.0368, -0.0603,  0.1336,\n",
      "        -0.0864, -0.0719])}, 9: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0272, -0.0630, -0.0683, -0.0574,  0.0033,  0.3173, -0.0188, -0.0735,\n",
      "        -0.0801,  0.0679])}, 8: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0301,  0.1861, -0.0950, -0.0800, -0.0339,  0.0782, -0.0282,  0.3186,\n",
      "        -0.2095, -0.1061])}, 3: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0676,  0.2311, -0.0689, -0.1136,  0.0401,  0.2702, -0.0784,  0.1902,\n",
      "        -0.2621, -0.1410])}, 2: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0847, -0.0020,  0.0921, -0.0381, -0.0501, -0.0592, -0.0350,  0.0583,\n",
      "        -0.0070, -0.0436])}}, 0: {0: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.1102,  0.1397, -0.1333, -0.0824,  0.1205,  0.2414,  0.0437, -0.0501,\n",
      "        -0.0918, -0.0774])}, 1: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0141, -0.0808, -0.0646, -0.0701,  0.0238,  0.6210, -0.0509, -0.0577,\n",
      "        -0.2624, -0.0442])}, 7: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.1192,  0.1308, -0.0593, -0.0570, -0.0084,  0.0115,  0.0321,  0.0546,\n",
      "        -0.1094,  0.1241])}, 6: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0960,  0.1720, -0.0041, -0.0571, -0.0764,  0.1930,  0.0212,  0.0118,\n",
      "        -0.0819, -0.0826])}, 9: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0935, -0.0927, -0.0886, -0.0499,  0.0587,  0.4203, -0.0455, -0.0834,\n",
      "        -0.0897,  0.0643])}, 8: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0772,  0.3091, -0.1156, -0.0949,  0.0007,  0.0997, -0.0645,  0.3810,\n",
      "        -0.3563, -0.0820])}, 3: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.1244,  0.3563, -0.1084, -0.1368,  0.1011,  0.3471, -0.1089,  0.2323,\n",
      "        -0.4259, -0.1325])}, 2: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0327,  0.0214,  0.0731, -0.0420, -0.0044, -0.0497, -0.0517,  0.0825,\n",
      "        -0.0277, -0.0342])}, 4: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0462, -0.0860, -0.0335,  0.2706,  0.1997, -0.0715, -0.0786,  0.0684,\n",
      "        -0.1785, -0.0444])}, 5: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0638,  0.0208,  0.2281, -0.0784, -0.0211, -0.0274, -0.0675,  0.1799,\n",
      "        -0.1071, -0.0634])}}, 2: {4: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0140, -0.0693, -0.0335,  0.2426,  0.1007, -0.1037, -0.0559,  0.0339,\n",
      "        -0.0715, -0.0573])}, 5: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0137, -0.0292,  0.2556, -0.0409, -0.0471, -0.0342, -0.0543,  0.1053,\n",
      "        -0.0836, -0.0579])}, 9: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0141, -0.0684, -0.0666, -0.0506,  0.0055,  0.2714, -0.0100, -0.0780,\n",
      "        -0.0717,  0.0824])}, 8: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0362,  0.1321, -0.0942, -0.0664, -0.0326,  0.0751, -0.0164,  0.2852,\n",
      "        -0.1450, -0.1017])}, 3: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0713,  0.1724, -0.0538, -0.0953,  0.0340,  0.2332, -0.0674,  0.1644,\n",
      "        -0.1900, -0.1262])}, 2: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0846, -0.0149,  0.0934, -0.0303, -0.0525, -0.0551, -0.0293,  0.0465,\n",
      "        -0.0045, -0.0380])}, 7: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0717,  0.0174,  0.0264,  0.0127, -0.0547, -0.0260,  0.0484,  0.0049,\n",
      "        -0.1093,  0.1519])}, 6: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0094,  0.0707,  0.0508, -0.0344, -0.0920,  0.1308,  0.0408, -0.0108,\n",
      "        -0.0736, -0.0729])}, 0: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0208,  0.0401, -0.0411, -0.0812,  0.0538,  0.1806,  0.0562, -0.0642,\n",
      "        -0.0961, -0.0273])}, 1: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0442, -0.0570, -0.0479, -0.0696, -0.0192,  0.4407, -0.0548, -0.0449,\n",
      "        -0.1411, -0.0502])}}, 5: {5: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0142, -0.0391,  0.2551, -0.0219, -0.0470, -0.0312, -0.0543,  0.0865,\n",
      "        -0.0800, -0.0539])}, 4: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0234, -0.0706, -0.0374,  0.2175,  0.0874, -0.1055, -0.0546,  0.0253,\n",
      "        -0.0311, -0.0546])}, 2: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0827, -0.0172,  0.0965, -0.0285, -0.0549, -0.0504, -0.0262,  0.0376,\n",
      "        -0.0019, -0.0378])}, 3: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0708,  0.1300, -0.0456, -0.0763,  0.0288,  0.1709, -0.0641,  0.1268,\n",
      "        -0.0815, -0.1180])}, 8: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0387,  0.0971, -0.0954, -0.0547, -0.0315,  0.0547, -0.0145,  0.2418,\n",
      "        -0.0626, -0.0962])}, 9: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0016, -0.0666, -0.0646, -0.0466,  0.0083,  0.2233, -0.0086, -0.0789,\n",
      "        -0.0595,  0.0947])}, 6: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0016,  0.0579,  0.0614, -0.0271, -0.0894,  0.1099,  0.0440, -0.0196,\n",
      "        -0.0704, -0.0684])}, 7: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0718,  0.0012,  0.0438,  0.0301, -0.0550, -0.0415,  0.0512, -0.0176,\n",
      "        -0.1052,  0.1649])}, 1: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0708, -0.0601, -0.0473, -0.0670, -0.0204,  0.3598, -0.0626, -0.0448,\n",
      "        -0.0772, -0.0510])}, 0: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0006,  0.0242, -0.0143, -0.0751,  0.0420,  0.1337,  0.0664, -0.0743,\n",
      "        -0.0969, -0.0063])}}, 4: {2: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0850, -0.0161,  0.0967, -0.0292, -0.0565, -0.0516, -0.0267,  0.0394,\n",
      "        -0.0041, -0.0370])}, 3: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0705,  0.1386, -0.0430, -0.0802,  0.0253,  0.1887, -0.0646,  0.1352,\n",
      "        -0.1162, -0.1135])}, 8: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0375,  0.1085, -0.0941, -0.0596, -0.0367,  0.0612, -0.0151,  0.2518,\n",
      "        -0.0811, -0.0973])}, 9: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0035, -0.0664, -0.0645, -0.0469,  0.0029,  0.2365, -0.0091, -0.0788,\n",
      "        -0.0640,  0.0937])}, 5: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0133, -0.0367,  0.2572, -0.0269, -0.0499, -0.0322, -0.0552,  0.0939,\n",
      "        -0.0820, -0.0549])}, 4: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0244, -0.0696, -0.0351,  0.2247,  0.0854, -0.1042, -0.0548,  0.0258,\n",
      "        -0.0437, -0.0528])}, 1: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0610, -0.0581, -0.0469, -0.0677, -0.0219,  0.3803, -0.0607, -0.0445,\n",
      "        -0.0916, -0.0499])}, 0: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0056,  0.0266, -0.0156, -0.0774,  0.0344,  0.1516,  0.0632, -0.0713,\n",
      "        -0.0972, -0.0087])}, 6: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([ 0.0017,  0.0619,  0.0580, -0.0280, -0.0930,  0.1129,  0.0443, -0.0173,\n",
      "        -0.0720, -0.0686])}, 7: {'fc.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'fc.bias': tensor([-0.0713,  0.0013,  0.0433,  0.0344, -0.0613, -0.0370,  0.0459, -0.0114,\n",
      "        -0.1081,  0.1642])}}}\n",
      "   round  node_id  eval_acc     exp               ts\n",
      "0      0        0    0.6809  benign  20250813-224933\n",
      "1      0        1    0.4007  benign  20250813-224933\n",
      "2      0        2    0.6351  benign  20250813-224933\n",
      "3      0        3    0.7508  benign  20250813-224933\n",
      "4      0        4    0.5404  benign  20250813-224933\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "RUNS = Path(\"/Users/yuandouwang/Documents/projects/federated_lab/runs\")\n",
    "\n",
    "# 1) One run (exp/timestamp folder)\n",
    "exp = \"benign\"          # e.g. use df_all[\"exp\"].unique()[0]\n",
    "ts  = \"20250813-224933\"  # e.g. use df_all[\"ts\"].unique()[0]\n",
    "df_one = reconstruct_and_eval_one_run(RUNS / exp / ts, dataset=\"mnist\", model_hint=\"linear-mnist\")\n",
    "print(df_one.head())\n",
    "\n",
    "# 2) All runs\n",
    "# df_all = reconstruct_and_eval_all_runs(RUNS, dataset=\"mnist\", model_hint=\"linear-mnist\")\n",
    "# print(df_all.groupby(\"round\")[\"eval_acc\"].mean().round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd24db8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FLSimulation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
