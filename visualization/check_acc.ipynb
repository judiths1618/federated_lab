{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89cae0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for runs in: /Users/yuandouwang/Documents/projects/federated_lab/runs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BASE = Path.cwd().resolve().parent / \"runs\"\n",
    "print(\"Looking for runs in:\", BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "444ef340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows: 170\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>global_acc</th>\n",
       "      <th>manifest_cid</th>\n",
       "      <th>node_id</th>\n",
       "      <th>samples</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>claimed_acc</th>\n",
       "      <th>eval_acc</th>\n",
       "      <th>acc_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>balance</th>\n",
       "      <th>stake_penalty</th>\n",
       "      <th>stake</th>\n",
       "      <th>reputation</th>\n",
       "      <th>malicious_detected</th>\n",
       "      <th>committee</th>\n",
       "      <th>is_malicious</th>\n",
       "      <th>strategy</th>\n",
       "      <th>exp</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7703</td>\n",
       "      <td>Qm00000022</td>\n",
       "      <td>0</td>\n",
       "      <td>7682</td>\n",
       "      <td>0.353403</td>\n",
       "      <td>0.914150</td>\n",
       "      <td>0.9141</td>\n",
       "      <td>0.6532</td>\n",
       "      <td>0.2609</td>\n",
       "      <td>...</td>\n",
       "      <td>74.5680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.5680</td>\n",
       "      <td>19.5688</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>benign</td>\n",
       "      <td>20250813-223511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7703</td>\n",
       "      <td>Qm00000022</td>\n",
       "      <td>1</td>\n",
       "      <td>6725</td>\n",
       "      <td>0.203163</td>\n",
       "      <td>0.945145</td>\n",
       "      <td>0.9451</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>0.5963</td>\n",
       "      <td>...</td>\n",
       "      <td>39.7479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.7479</td>\n",
       "      <td>19.0325</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>benign</td>\n",
       "      <td>20250813-223511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7703</td>\n",
       "      <td>Qm00000022</td>\n",
       "      <td>2</td>\n",
       "      <td>1321</td>\n",
       "      <td>0.341979</td>\n",
       "      <td>0.912869</td>\n",
       "      <td>0.9129</td>\n",
       "      <td>0.3931</td>\n",
       "      <td>0.5198</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0427</td>\n",
       "      <td>18.4381</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>benign</td>\n",
       "      <td>20250813-223511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   round  global_acc manifest_cid  node_id  samples      loss       acc  \\\n",
       "0      0      0.7703   Qm00000022        0     7682  0.353403  0.914150   \n",
       "1      0      0.7703   Qm00000022        1     6725  0.203163  0.945145   \n",
       "2      0      0.7703   Qm00000022        2     1321  0.341979  0.912869   \n",
       "\n",
       "   claimed_acc  eval_acc  acc_diff  ...  balance stake_penalty     stake  \\\n",
       "0       0.9141    0.6532    0.2609  ...  74.5680           0.0  174.5680   \n",
       "1       0.9451    0.3488    0.5963  ...  39.7479           0.0  139.7479   \n",
       "2       0.9129    0.3931    0.5198  ...  26.0427           0.0  126.0427   \n",
       "\n",
       "   reputation  malicious_detected  committee  is_malicious  strategy     exp  \\\n",
       "0     19.5688                   1          1             0      none  benign   \n",
       "1     19.0325                   1          1             0      none  benign   \n",
       "2     18.4381                   1          1             0      none  benign   \n",
       "\n",
       "                ts  \n",
       "0  20250813-223511  \n",
       "1  20250813-223511  \n",
       "2  20250813-223511  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_all_runs(runs_root: Path) -> pd.DataFrame:\n",
    "    runs_root = runs_root if runs_root.name == \"runs\" else (runs_root / \"runs\")\n",
    "    rows = []\n",
    "    if not runs_root.exists():\n",
    "        print(\"No runs folder found:\", runs_root)\n",
    "        return pd.DataFrame()\n",
    "    for exp_dir in sorted(runs_root.glob(\"*\")):\n",
    "        if not exp_dir.is_dir():\n",
    "            continue\n",
    "        for ts_dir in sorted(exp_dir.glob(\"*\")):\n",
    "            csv_path = ts_dir / \"fl_log.csv\"\n",
    "            if csv_path.exists():\n",
    "                try:\n",
    "                    df = pd.read_csv(csv_path)\n",
    "                    df[\"exp\"] = exp_dir.name\n",
    "                    df[\"ts\"] = ts_dir.name\n",
    "                    rows.append(df)\n",
    "                except Exception as e:\n",
    "                    print(\"Failed to read\", csv_path, e)\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "    return pd.concat(rows, ignore_index=True)\n",
    "\n",
    "df = load_all_runs(BASE)\n",
    "print(\"Loaded rows:\", len(df))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dcd1f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Using artifacts from] /Users/yuandouwang/Documents/projects/federated_lab/runs/benign/20250813-224933\n",
      "[Warn] No base model found for round 0 in /Users/yuandouwang/Documents/projects/federated_lab/runs/benign/20250813-224933/models, skipping this round.\n",
      "    round  node       acc      loss    n  missing_keys  unexpected_keys  \\\n",
      "0       1     0  0.109375  2.308768  256             4                2   \n",
      "1       1     1  0.125000  2.293167  256             4                2   \n",
      "2       1     2  0.089844  2.342567  256             4                2   \n",
      "3       1     3  0.109375  2.336424  256             4                2   \n",
      "4       1     4  0.097656  2.310634  256             4                2   \n",
      "5       1     5  0.121094  2.339877  256             4                2   \n",
      "6       1     6  0.082031  2.341358  256             4                2   \n",
      "7       1     7  0.101562  2.321245  256             4                2   \n",
      "8       1     8  0.101562  2.324399  256             4                2   \n",
      "9       1     9  0.085938  2.322429  256             4                2   \n",
      "10      2     0  0.089844  2.332953  256             4                2   \n",
      "11      2     1  0.121094  2.336688  256             4                2   \n",
      "12      2     2  0.082031  2.327041  256             4                2   \n",
      "13      2     3  0.097656  2.334633  256             4                2   \n",
      "14      2     4  0.082031  2.322237  256             4                2   \n",
      "15      2     5  0.148438  2.314016  256             4                2   \n",
      "16      2     6  0.117188  2.302431  256             4                2   \n",
      "17      2     7  0.105469  2.321384  256             4                2   \n",
      "18      2     8  0.097656  2.340859  256             4                2   \n",
      "19      2     9  0.082031  2.331025  256             4                2   \n",
      "20      3     0  0.097656  2.336401  256             4                2   \n",
      "21      3     1  0.121094  2.306995  256             4                2   \n",
      "22      3     2  0.074219  2.374180  256             4                2   \n",
      "23      3     3  0.089844  2.322290  256             4                2   \n",
      "24      3     4  0.113281  2.360406  256             4                2   \n",
      "25      3     5  0.128906  2.294793  256             4                2   \n",
      "26      3     6  0.113281  2.321352  256             4                2   \n",
      "27      3     7  0.117188  2.315266  256             4                2   \n",
      "28      3     8  0.093750  2.342693  256             4                2   \n",
      "29      3     9  0.109375  2.330475  256             4                2   \n",
      "30      4     0  0.082031  2.335098  256             4                2   \n",
      "31      4     1  0.121094  2.310269  256             4                2   \n",
      "32      4     2  0.093750  2.336749  256             4                2   \n",
      "33      4     3  0.125000  2.310389  256             4                2   \n",
      "34      4     4  0.093750  2.343911  256             4                2   \n",
      "35      4     5  0.097656  2.314357  256             4                2   \n",
      "36      4     6  0.070312  2.351659  256             4                2   \n",
      "37      4     7  0.113281  2.306708  256             4                2   \n",
      "38      4     8  0.093750  2.317029  256             4                2   \n",
      "39      4     9  0.089844  2.361771  256             4                2   \n",
      "40      5     0  0.132812  2.298472  256             4                2   \n",
      "41      5     1  0.113281  2.291960  256             4                2   \n",
      "42      5     2  0.128906  2.315366  256             4                2   \n",
      "43      5     3  0.128906  2.304282  256             4                2   \n",
      "44      5     4  0.109375  2.327817  256             4                2   \n",
      "45      5     5  0.132812  2.306734  256             4                2   \n",
      "46      5     6  0.117188  2.324192  256             4                2   \n",
      "47      5     7  0.074219  2.322436  256             4                2   \n",
      "48      5     8  0.117188  2.326946  256             4                2   \n",
      "49      5     9  0.109375  2.345106  256             4                2   \n",
      "\n",
      "                 delta_file  \n",
      "0   round_1_node_0_delta.pt  \n",
      "1   round_1_node_1_delta.pt  \n",
      "2   round_1_node_2_delta.pt  \n",
      "3   round_1_node_3_delta.pt  \n",
      "4   round_1_node_4_delta.pt  \n",
      "5   round_1_node_5_delta.pt  \n",
      "6   round_1_node_6_delta.pt  \n",
      "7   round_1_node_7_delta.pt  \n",
      "8   round_1_node_8_delta.pt  \n",
      "9   round_1_node_9_delta.pt  \n",
      "10  round_2_node_0_delta.pt  \n",
      "11  round_2_node_1_delta.pt  \n",
      "12  round_2_node_2_delta.pt  \n",
      "13  round_2_node_3_delta.pt  \n",
      "14  round_2_node_4_delta.pt  \n",
      "15  round_2_node_5_delta.pt  \n",
      "16  round_2_node_6_delta.pt  \n",
      "17  round_2_node_7_delta.pt  \n",
      "18  round_2_node_8_delta.pt  \n",
      "19  round_2_node_9_delta.pt  \n",
      "20  round_3_node_0_delta.pt  \n",
      "21  round_3_node_1_delta.pt  \n",
      "22  round_3_node_2_delta.pt  \n",
      "23  round_3_node_3_delta.pt  \n",
      "24  round_3_node_4_delta.pt  \n",
      "25  round_3_node_5_delta.pt  \n",
      "26  round_3_node_6_delta.pt  \n",
      "27  round_3_node_7_delta.pt  \n",
      "28  round_3_node_8_delta.pt  \n",
      "29  round_3_node_9_delta.pt  \n",
      "30  round_4_node_0_delta.pt  \n",
      "31  round_4_node_1_delta.pt  \n",
      "32  round_4_node_2_delta.pt  \n",
      "33  round_4_node_3_delta.pt  \n",
      "34  round_4_node_4_delta.pt  \n",
      "35  round_4_node_5_delta.pt  \n",
      "36  round_4_node_6_delta.pt  \n",
      "37  round_4_node_7_delta.pt  \n",
      "38  round_4_node_8_delta.pt  \n",
      "39  round_4_node_9_delta.pt  \n",
      "40  round_5_node_0_delta.pt  \n",
      "41  round_5_node_1_delta.pt  \n",
      "42  round_5_node_2_delta.pt  \n",
      "43  round_5_node_3_delta.pt  \n",
      "44  round_5_node_4_delta.pt  \n",
      "45  round_5_node_5_delta.pt  \n",
      "46  round_5_node_6_delta.pt  \n",
      "47  round_5_node_7_delta.pt  \n",
      "48  round_5_node_8_delta.pt  \n",
      "49  round_5_node_9_delta.pt  \n"
     ]
    }
   ],
   "source": [
    "# Federated evaluation across rounds & nodes using base + delta reconstruction.\n",
    "# - Auto-discovers files like:\n",
    "#     models/global_round_{r}_base.pt (or fallback: global_round_{r}.pt)\n",
    "#     updates/round_{r}_node_{i}_delta.pt\n",
    "# - Reconstructs each node's local model: base + delta\n",
    "# - Evaluates accuracy on a test loader (replace with your real test loader)\n",
    "# - Summarizes results in a DataFrame and saves CSV\n",
    "#\n",
    "# If no artifacts are found at the default path, this will run a synthetic demo\n",
    "# so you can see the full pipeline and results format.\n",
    "#\n",
    "# === HOW TO ADAPT ===\n",
    "# 1) Set RUN_DIR to your run folder containing \"models\" and \"updates\".\n",
    "# 2) Replace MODEL_FACTORY() with your actual model constructor.\n",
    "# 3) Replace build_test_loader() with your real test DataLoader.\n",
    "# 4) If your .pt files are full models (not state_dict), adjust load logic.\n",
    "#\n",
    "# Files will be saved to /mnt/data, including results CSV.\n",
    "\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from typing import Dict, Any\n",
    "\n",
    "# -----------------------------\n",
    "# Config: paths\n",
    "# -----------------------------\n",
    "# Try to auto-detect a likely run dir under /mnt/data/runs/benign/*\n",
    "\n",
    "CANDIDATE = None\n",
    "runs_root = BASE / \"runs\" / \"benign\"\n",
    "if runs_root.exists():\n",
    "    # pick the most recently modified child that has both models/ and updates/\n",
    "    candidates = []\n",
    "    for p in runs_root.glob(\"*\"):\n",
    "        if p.is_dir() and (p / \"models\").exists() and (p / \"updates\").exists():\n",
    "            candidates.append((p.stat().st_mtime, p))\n",
    "    if candidates:\n",
    "        CANDIDATE = sorted(candidates, key=lambda x: x[0], reverse=True)[0][1]\n",
    "\n",
    "# Allow the user to change this path if needed:\n",
    "RUN_DIR = CANDIDATE if CANDIDATE else (BASE / \"benign\" / \"20250813-224933\")\n",
    "MODELS_DIR = RUN_DIR / \"models\"\n",
    "UPDATES_DIR = RUN_DIR / \"updates\"\n",
    "\n",
    "# -----------------------------\n",
    "# Config: model + test loader\n",
    "# -----------------------------\n",
    "NUM_CLASSES = 10\n",
    "IMAGE_SHAPE = (1, 28, 28)\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(IMAGE_SHAPE[0]*IMAGE_SHAPE[1]*IMAGE_SHAPE[2], 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def MODEL_FACTORY():\n",
    "    # TODO: replace with your real model constructor\n",
    "    return SimpleNet(num_classes=NUM_CLASSES)\n",
    "\n",
    "def build_test_loader():\n",
    "    # TODO: replace with your real test dataset/loader\n",
    "    X_test = torch.randn(256, *IMAGE_SHAPE)\n",
    "    y_test = torch.randint(0, NUM_CLASSES, (256,))\n",
    "    return DataLoader(TensorDataset(X_test, y_test), batch_size=64)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def reconstruct_full_state(base_state: Dict[str, torch.Tensor],\n",
    "                           delta_state: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "    full = {}\n",
    "    for k, base_tensor in base_state.items():\n",
    "        if k in delta_state:\n",
    "            full[k] = base_tensor + delta_state[k]\n",
    "        else:\n",
    "            full[k] = base_tensor\n",
    "    for k, v in delta_state.items():\n",
    "        if k not in full:\n",
    "            full[k] = v\n",
    "    return full\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module, loader: DataLoader) -> Dict[str, Any]:\n",
    "    model.eval()\n",
    "    total, correct, total_loss = 0, 0, 0.0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += yb.numel()\n",
    "        total_loss += loss.item() * yb.size(0)\n",
    "    acc = correct / total if total > 0 else 0.0\n",
    "    avg_loss = total_loss / total if total > 0 else 0.0\n",
    "    return {\"acc\": acc, \"loss\": avg_loss, \"n\": total}\n",
    "\n",
    "def find_rounds_nodes(updates_dir: Path):\n",
    "    # pattern: round_{r}_node_{i}_delta.pt\n",
    "    pat = re.compile(r\"round_(\\d+)_node_(\\d+)_delta\\.pt$\")\n",
    "    mapping = {}\n",
    "    if not updates_dir.exists():\n",
    "        return mapping\n",
    "    for f in updates_dir.glob(\"*.pt\"):\n",
    "        m = pat.search(f.name)\n",
    "        if m:\n",
    "            r = int(m.group(1))\n",
    "            i = int(m.group(2))\n",
    "            mapping.setdefault(r, []).append((i, f))\n",
    "    # sort nodes by id per round\n",
    "    for r in mapping:\n",
    "        mapping[r] = sorted(mapping[r], key=lambda x: x[0])\n",
    "    return dict(sorted(mapping.items(), key=lambda x: x[0]))\n",
    "\n",
    "def load_base_for_round(models_dir: Path, r: int):\n",
    "    # prefer global_round_{r}_base.pt else fallback to global_round_{r}.pt\n",
    "    base1 = models_dir / f\"global_round_{r-1}_base.pt\"\n",
    "    base2 = models_dir / f\"global_round_{r-1}.pt\"\n",
    "    if base1.exists():\n",
    "        return torch.load(base1, map_location=\"cpu\")\n",
    "    if base2.exists():\n",
    "        return torch.load(base2, map_location=\"cpu\")\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# Main evaluation\n",
    "# -----------------------------\n",
    "test_loader = build_test_loader()\n",
    "\n",
    "results = []\n",
    "artifact_found = MODELS_DIR.exists() and UPDATES_DIR.exists()\n",
    "if artifact_found:\n",
    "    rounds = find_rounds_nodes(UPDATES_DIR)\n",
    "    if not rounds:\n",
    "        print(f\"[Info] No update deltas found under {UPDATES_DIR}. Running synthetic demo instead.\")\n",
    "        artifact_found = False\n",
    "\n",
    "if artifact_found:\n",
    "    print(f\"[Using artifacts from] {RUN_DIR}\")\n",
    "    for r, node_list in rounds.items():\n",
    "        base_state = load_base_for_round(MODELS_DIR, r)\n",
    "        if base_state is None:\n",
    "            print(f\"[Warn] No base model found for round {r} in {MODELS_DIR}, skipping this round.\")\n",
    "            continue\n",
    "        for node_id, delta_path in node_list:\n",
    "            try:\n",
    "                delta_state = torch.load(delta_path, map_location=\"cpu\")\n",
    "            except Exception as e:\n",
    "                print(f\"[Error] Could not load delta {delta_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # reconstruct\n",
    "            reconstructed_state = reconstruct_full_state(base_state, delta_state)\n",
    "            model = MODEL_FACTORY().to(device)\n",
    "            try:\n",
    "                missing, unexpected = model.load_state_dict(reconstructed_state, strict=False)\n",
    "            except Exception as e:\n",
    "                print(f\"[Error] load_state_dict failed for round {r}, node {node_id}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # evaluate\n",
    "            metrics = evaluate(model, test_loader)\n",
    "            results.append({\n",
    "                \"round\": r,\n",
    "                \"node\": node_id,\n",
    "                \"acc\": metrics[\"acc\"],\n",
    "                \"loss\": metrics[\"loss\"],\n",
    "                \"n\": metrics[\"n\"],\n",
    "                \"missing_keys\": len(missing),\n",
    "                \"unexpected_keys\": len(unexpected),\n",
    "                \"delta_file\": str(delta_path.name)\n",
    "            })\n",
    "else:\n",
    "    # Synthetic demo so the pipeline is visible and results are produced\n",
    "    print(\"[Demo] No real artifacts detected. Running a synthetic demonstration.\")\n",
    "    # Create a base model\n",
    "    base_model = MODEL_FACTORY().to(device)\n",
    "    base_state = base_model.state_dict()\n",
    "    # Simulate 2 rounds Ã— 3 nodes with small random deltas\n",
    "    for r in range(2):\n",
    "        for node_id in range(3):\n",
    "            delta_state = {k: torch.randn_like(v) * 0.01 for k, v in base_state.items()}\n",
    "            reconstructed_state = reconstruct_full_state(base_state, delta_state)\n",
    "            model = MODEL_FACTORY().to(device)\n",
    "            model.load_state_dict(reconstructed_state, strict=False)\n",
    "            metrics = evaluate(model, test_loader)\n",
    "            results.append({\n",
    "                \"round\": r,\n",
    "                \"node\": node_id,\n",
    "                \"acc\": metrics[\"acc\"],\n",
    "                \"loss\": metrics[\"loss\"],\n",
    "                \"n\": metrics[\"n\"],\n",
    "                \"missing_keys\": 0,\n",
    "                \"unexpected_keys\": 0,\n",
    "                \"delta_file\": f\"synthetic_round_{r}_node_{node_id}_delta\"\n",
    "            })\n",
    "\n",
    "# -----------------------------\n",
    "# Save & show results\n",
    "# -----------------------------\n",
    "df = pd.DataFrame(results).sort_values([\"round\", \"node\"]).reset_index(drop=True)\n",
    "print(df)\n",
    "# out_csv = \"/mnt/data/per_node_accuracy_by_round.csv\"\n",
    "# df.to_csv(out_csv, index=False)\n",
    "\n",
    "# Display table to the user in the UI\n",
    "# %pip install caas_jupyter_tools\n",
    "\n",
    "# from caas_jupyter_tools import display_dataframe_to_user\n",
    "# display_dataframe_to_user(\"Per-node accuracy by round\", df)\n",
    "\n",
    "# print(f\"\\nSaved results to: {out_csv}\")\n",
    "# print(f\"RUN_DIR used: {RUN_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FLSimulation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
